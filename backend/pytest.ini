[pytest]
# ============================================================================
# ORFEAS AI 2Dâ†’3D Studio - pytest Configuration
# ============================================================================
# Author: THERION Protocol - Code Quality Master
# Date: October 14, 2025
# Purpose: Professional pytest configuration for comprehensive test suite
# ============================================================================

# Test Discovery
# ============================================================================
python_files = test_*.py *_test.py
python_classes = Test*
python_functions = test_*
testpaths = tests

# Test Organization
# ============================================================================
# Use markers to organize tests by category
markers =
    unit: Unit tests (fast, isolated, no external dependencies)
    integration: Integration tests (API tests, require running server)
    security: Security tests (vulnerability scanning, validation)
    performance: Performance tests (load testing, benchmarking)
    slow: Slow-running tests (can be skipped with -m 'not slow')
    smoke: Smoke tests (critical path validation)
    regression: Regression tests (prevent known bugs)
    requires_models: Tests requiring Hunyuan3D models and GPU
    gpu: Tests requiring GPU acceleration

# Output Configuration
# ============================================================================
# Verbose output with detailed information
addopts =
    -v
    --strict-markers
    --tb=short
    --disable-warnings
    --color=yes
    --showlocals
    --durations=10
    --maxfail=5
    -ra
    --cov=.
    --cov-report=html
    --cov-report=term-missing
    --cov-config=.coveragerc

# Console Output
# ============================================================================
console_output_style = progress
log_cli = true
log_cli_level = INFO
log_cli_format = %(asctime)s [%(levelname)8s] %(message)s
log_cli_date_format = %Y-%m-%d %H:%M:%S

# File Logging
# ============================================================================
log_file = tests/pytest.log
log_file_level = DEBUG
log_file_format = %(asctime)s [%(levelname)8s] [%(filename)s:%(lineno)d] %(message)s
log_file_date_format = %Y-%m-%d %H:%M:%S

# Coverage Configuration
# ============================================================================
# Minimum coverage threshold: 80%
# Reports generated in htmlcov/ directory
# Focus on backend/*.py files, exclude tests

# Timeout Configuration
# ============================================================================
# Prevent hung tests from blocking CI/CD
timeout = 300
timeout_method = thread

# Warnings Configuration
# ============================================================================
filterwarnings =
    error
    ignore::UserWarning
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::ImportWarning

# Async Support
# ============================================================================
asyncio_mode = auto

# Fixtures
# ============================================================================
# Use tests/conftest.py for shared fixtures
# Automatic fixture discovery

# Parallel Execution
# ============================================================================
# Use pytest-xdist for parallel test execution
# Run with: pytest -n auto
# Disabled by default to avoid race conditions

# Test Selection Examples
# ============================================================================
# Run only unit tests:          pytest -m unit
# Run integration tests:        pytest -m integration
# Run security tests:           pytest -m security
# Skip slow tests:              pytest -m 'not slow'
# Run smoke tests only:         pytest -m smoke
# Run specific file:            pytest tests/unit/test_validation.py
# Run specific test:            pytest tests/unit/test_validation.py::test_secret_key
# Run with coverage:            pytest --cov=. --cov-report=html
# Run in parallel:              pytest -n auto
# Run with detailed output:     pytest -vv
# Stop on first failure:        pytest -x
# Re-run failed tests:          pytest --lf
# Run tests changed in git:     pytest --picked

# Performance Tuning
# ============================================================================
# Cache test results for faster re-runs
cache_dir = .pytest_cache

# Don't capture output during tests (useful for debugging)
# Uncomment to see print statements during test execution
# addopts = -s

# Environment Variables
# ============================================================================
# Set test-specific environment variables
env =
    TESTING=true
    FLASK_ENV=testing
    SECRET_KEY=test-secret-key-for-testing-only-32chars-long
    CORS_ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
    RATE_LIMIT_PER_MINUTE=100

# ============================================================================
# USAGE GUIDE
# ============================================================================
#
# Quick Start:
#   pytest                      # Run all tests
#   pytest -v                   # Verbose output
#   pytest -k "text_to_image"   # Run tests matching keyword
#   pytest --lf                 # Run last failed tests
#   pytest --ff                 # Run failures first
#
# By Category:
#   pytest -m unit              # Only unit tests (fast)
#   pytest -m integration       # Only integration tests
#   pytest -m "not slow"        # Skip slow tests
#   pytest -m "security or smoke" # Multiple markers
#
# Coverage:
#   pytest --cov=. --cov-report=html    # Generate HTML coverage report
#   pytest --cov=. --cov-report=term    # Show coverage in terminal
#   open htmlcov/index.html             # View coverage report
#
# Debugging:
#   pytest -vv                  # Extra verbose
#   pytest -s                   # Show print statements
#   pytest --pdb                # Drop into debugger on failure
#   pytest --trace              # Drop into debugger at test start
#   pytest --showlocals         # Show local variables on failure
#
# Performance:
#   pytest -n auto              # Run tests in parallel
#   pytest --durations=10       # Show 10 slowest tests
#   pytest -m "not slow"        # Skip slow tests
#
# CI/CD:
#   pytest -v --tb=short --maxfail=5 --cov=. --cov-report=xml
#
# ============================================================================
