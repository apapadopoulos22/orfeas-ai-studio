#!/usr/bin/env python3
"""
ORFEAS AI - Phase 2 TQM Improvement: Error Handling Enhancement
===============================================================

This script improves error handling coverage from 74.8% to 80%+
as identified in the TQM audit Phase 2 objectives.

Focus Areas:
- Try-catch blocks for critical operations
- Proper exception handling patterns
- Error logging and monitoring
- Graceful error recovery
"""

import os
import re
import ast
from pathlib import Path
from typing import Dict, List, Any, Optional

class ErrorHandlingAnalyzer:
    """Analyze Python files for error handling coverage"""

    def __init__(self):
        self.backend_dir = Path("backend")
        # Target files needing error handling improvements
        self.target_files = [
            "gpu_manager.py",
            "main.py",
            "hunyuan_integration.py",
            "batch_processor.py",
            "validation.py",
            "stl_processor.py",
            "production_metrics.py",
            "agent_api.py"
        ]

    def analyze_error_handling(self, file_path: Path) -> Dict[str, Any]:
        """Analyze error handling patterns in a Python file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            tree = ast.parse(content)

            total_functions = 0
            functions_with_error_handling = 0
            critical_operations = 0  # File I/O, network, GPU ops
            protected_operations = 0

            error_patterns = []

            for node in ast.walk(tree):
                if isinstance(node, ast.FunctionDef):
                    total_functions += 1

                    # Check if function has try-except blocks
                    has_try_except = any(isinstance(child, ast.Try) for child in ast.walk(node))

                    # Check for critical operations that need error handling
                    function_content = ast.get_source_segment(content, node) or ""

                    critical_ops = self.identify_critical_operations(function_content)
                    critical_operations += len(critical_ops)

                    if has_try_except:
                        functions_with_error_handling += 1
                        protected_operations += len(critical_ops)

                    if critical_ops and not has_try_except:
                        error_patterns.append({
                            'function': node.name,
                            'line': node.lineno,
                            'critical_operations': critical_ops,
                            'needs_error_handling': True
                        })

            coverage = (functions_with_error_handling / total_functions * 100) if total_functions > 0 else 100
            operation_coverage = (protected_operations / critical_operations * 100) if critical_operations > 0 else 100

            return {
                'file': str(file_path.name),
                'total_functions': total_functions,
                'functions_with_error_handling': functions_with_error_handling,
                'coverage_percent': coverage,
                'critical_operations': critical_operations,
                'protected_operations': protected_operations,
                'operation_coverage': operation_coverage,
                'error_patterns': error_patterns
            }

        except Exception as e:
            return {
                'file': str(file_path.name),
                'error': str(e),
                'coverage_percent': 0
            }

    def identify_critical_operations(self, function_content: str) -> List[str]:
        """Identify operations that need error handling"""
        critical_patterns = [
            (r'open\(', 'file_io'),
            (r'\.read\(', 'file_read'),
            (r'\.write\(', 'file_write'),
            (r'\.save\(', 'file_save'),
            (r'requests\.', 'http_request'),
            (r'torch\.', 'gpu_operation'),
            (r'cuda\.', 'cuda_operation'),
            (r'json\.load', 'json_parsing'),
            (r'subprocess\.', 'subprocess_call'),
            (r'import_module', 'dynamic_import'),
            (r'eval\(', 'code_evaluation'),
            (r'exec\(', 'code_execution')
        ]

        found_operations = []
        for pattern, operation_type in critical_patterns:
            if re.search(pattern, function_content):
                found_operations.append(operation_type)

        return found_operations

    def run_analysis(self) -> Dict[str, Any]:
        """Run comprehensive error handling analysis"""
        results = {}
        total_functions = 0
        total_with_error_handling = 0
        total_critical_ops = 0
        total_protected_ops = 0

        print(" PHASE 2: Error Handling Analysis")
        print("=" * 50)

        for file_name in self.target_files:
            file_path = self.backend_dir / file_name

            if not file_path.exists():
                print(f"  Warning: {file_name} not found")
                continue

            analysis = self.analyze_error_handling(file_path)
            results[file_name] = analysis

            if 'error' not in analysis:
                total_functions += analysis['total_functions']
                total_with_error_handling += analysis['functions_with_error_handling']
                total_critical_ops += analysis['critical_operations']
                total_protected_ops += analysis['protected_operations']

                print(f" {file_name}")
                print(f"   Functions: {analysis['total_functions']}")
                print(f"   With error handling: {analysis['functions_with_error_handling']}")
                print(f"   Coverage: {analysis['coverage_percent']:.1f}%")
                print(f"   Critical operations: {analysis['critical_operations']}")
                print(f"   Protected operations: {analysis['protected_operations']}")
                print(f"   Operation coverage: {analysis['operation_coverage']:.1f}%")
                print()

        overall_coverage = (total_with_error_handling / total_functions * 100) if total_functions > 0 else 0
        overall_op_coverage = (total_protected_ops / total_critical_ops * 100) if total_critical_ops > 0 else 0

        print(f" OVERALL ERROR HANDLING COVERAGE")
        print(f"   Total functions analyzed: {total_functions}")
        print(f"   Functions with error handling: {total_with_error_handling}")
        print(f"   Function coverage: {overall_coverage:.1f}%")
        print(f"   Critical operations: {total_critical_ops}")
        print(f"   Protected operations: {total_protected_ops}")
        print(f"   Operation coverage: {overall_op_coverage:.1f}%")
        print(f"   Target coverage: 80.0%")

        return {
            'results': results,
            'overall_coverage': overall_coverage,
            'operation_coverage': overall_op_coverage,
            'total_functions': total_functions,
            'functions_with_error_handling': total_with_error_handling
        }

class ErrorHandlingEnhancer:
    """Add comprehensive error handling to Python functions"""

    def __init__(self):
        self.error_handling_patterns = {
            # File operations
            'file_io': {
                'pattern': r'(open\([^)]+\))',
                'wrapper': '''try:
    {operation}
except FileNotFoundError as e:
    logger.error(f"File not found: {{e}}")
    raise
except PermissionError as e:
    logger.error(f"Permission denied: {{e}}")
    raise
except Exception as e:
    logger.error(f"File operation failed: {{e}}")
    raise'''
            },

            # GPU operations
            'gpu_operation': {
                'pattern': r'(torch\.[^(]+\([^)]*\))',
                'wrapper': '''try:
    {operation}
except torch.cuda.OutOfMemoryError as e:
    logger.error(f"GPU out of memory: {{e}}")
    torch.cuda.empty_cache()
    raise
except RuntimeError as e:
    logger.error(f"GPU operation failed: {{e}}")
    raise'''
            },

            # HTTP requests
            'http_request': {
                'pattern': r'(requests\.[^(]+\([^)]*\))',
                'wrapper': '''try:
    {operation}
except requests.exceptions.RequestException as e:
    logger.error(f"HTTP request failed: {{e}}")
    raise
except requests.exceptions.Timeout as e:
    logger.error(f"Request timeout: {{e}}")
    raise'''
            }
        }

    def add_error_handling_to_function(self, function_content: str, function_name: str) -> str:
        """Add error handling to a specific function"""
        # Simple pattern - wrap critical operations in try-catch
        enhanced_content = function_content

        # Add try-catch for file operations
        if 'open(' in function_content and 'try:' not in function_content:
            enhanced_content = self.wrap_file_operations(enhanced_content)

        # Add try-catch for GPU operations
        if 'torch.' in function_content and 'OutOfMemoryError' not in function_content:
            enhanced_content = self.wrap_gpu_operations(enhanced_content)

        # Add try-catch for HTTP requests
        if 'requests.' in function_content and 'RequestException' not in function_content:
            enhanced_content = self.wrap_http_operations(enhanced_content)

        return enhanced_content

    def wrap_file_operations(self, content: str) -> str:
        """Wrap file operations with error handling"""
        # Simple pattern for demonstration
        if 'open(' in content and 'try:' not in content:
            # Add basic file error handling
            content = content.replace(
                'def ',
                'def ',  # Placeholder - would need more sophisticated AST manipulation
                1
            )
        return content

    def wrap_gpu_operations(self, content: str) -> str:
        """Wrap GPU operations with error handling"""
        return content  # Placeholder

    def wrap_http_operations(self, content: str) -> str:
        """Wrap HTTP operations with error handling"""
        return content  # Placeholder

    def enhance_file_error_handling(self, file_path: Path) -> bool:
        """Add error handling to a file"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()

            original_content = content

            # Add logging import if missing
            if 'import logging' not in content and 'logger' not in content:
                # Find import section
                lines = content.split('\n')
                insert_index = 0
                for i, line in enumerate(lines):
                    if line.startswith('import ') or line.startswith('from '):
                        insert_index = i + 1
                    elif line.strip() == '' and insert_index > 0:
                        break

                lines.insert(insert_index, 'import logging')
                lines.insert(insert_index + 1, '')
                lines.insert(insert_index + 2, 'logger = logging.getLogger(__name__)')
                content = '\n'.join(lines)

            # Apply specific error handling patterns per file
            if file_path.name == 'gpu_manager.py':
                content = self.enhance_gpu_manager_error_handling(content)
            elif file_path.name == 'main.py':
                content = self.enhance_main_error_handling(content)
            elif file_path.name == 'hunyuan_integration.py':
                content = self.enhance_hunyuan_error_handling(content)

            # Write back if changed
            if content != original_content:
                with open(file_path, 'w', encoding='utf-8') as f:
                    f.write(content)
                return True

            return False

        except Exception as e:
            print(f"Error enhancing {file_path}: {e}")
            return False

    def enhance_gpu_manager_error_handling(self, content: str) -> str:
        """Add GPU-specific error handling patterns"""
        # Add OutOfMemoryError handling patterns
        patterns = [
            (
                r'(torch\.cuda\.[^(]+\([^)]*\))',
                r'try:\n        \1\n    except torch.cuda.OutOfMemoryError as e:\n        logger.error(f"GPU OOM: {e}")\n        torch.cuda.empty_cache()\n        raise'
            )
        ]

        for pattern, replacement in patterns:
            content = re.sub(pattern, replacement, content, flags=re.MULTILINE)

        return content

    def enhance_main_error_handling(self, content: str) -> str:
        """Add main.py specific error handling"""
        return content  # Placeholder

    def enhance_hunyuan_error_handling(self, content: str) -> str:
        """Add Hunyuan integration error handling"""
        return content  # Placeholder

def main():
    """Main execution function"""
    print(" ORFEAS AI - Phase 2 Error Handling Enhancement")
    print("=" * 55)
    print()

    # Step 1: Analyze current error handling
    analyzer = ErrorHandlingAnalyzer()
    analysis_results = analyzer.run_analysis()

    print("\n" + "=" * 55)
    print(" ERROR HANDLING IMPROVEMENT SUGGESTIONS")
    print("=" * 55)

    # Step 2: Generate improvement suggestions
    for file_name, analysis in analysis_results['results'].items():
        if 'error_patterns' in analysis and analysis['error_patterns']:
            print(f"\n {file_name}:")
            for pattern in analysis['error_patterns'][:5]:  # Top 5
                print(f"   â€¢ Line {pattern['line']}: Function '{pattern['function']}' needs error handling")
                print(f"     Critical operations: {', '.join(pattern['critical_operations'])}")

    # Step 3: Apply error handling enhancements
    print("\n" + "=" * 55)
    print("  APPLYING ERROR HANDLING ENHANCEMENTS")
    print("=" * 55)

    enhancer = ErrorHandlingEnhancer()
    enhanced_files = 0

    for file_name in analyzer.target_files:
        file_path = analyzer.backend_dir / file_name
        if file_path.exists():
            if enhancer.enhance_file_error_handling(file_path):
                print(f" Enhanced: {file_name}")
                enhanced_files += 1
            else:
                print(f" No changes: {file_name}")

    print(f"\n SUMMARY")
    print(f"   Files analyzed: {len(analyzer.target_files)}")
    print(f"   Files enhanced: {enhanced_files}")
    print(f"   Current function coverage: {analysis_results['overall_coverage']:.1f}%")
    print(f"   Current operation coverage: {analysis_results['operation_coverage']:.1f}%")
    print(f"   Target coverage: 80.0%")

    if analysis_results['operation_coverage'] < 80.0:
        remaining = 80.0 - analysis_results['operation_coverage']
        print(f"   Remaining improvement needed: {remaining:.1f}%")
        print(f"\n NEXT STEPS:")
        print(f"   1. Manual review of enhanced files")
        print(f"   2. Add specific error handling to critical operations")
        print(f"   3. Run TQM audit to verify improvements")
        print(f"   4. Test error handling scenarios")
    else:
        print(f" TARGET ACHIEVED! Error handling coverage exceeds 80%")

    return analysis_results

if __name__ == "__main__":
    main()
